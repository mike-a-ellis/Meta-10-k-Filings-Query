{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install all of this :\n",
    "#chainlit==0.7.700\n",
    "# cohere==4.37\n",
    "# openai==1.23.6\n",
    "# tiktoken==0.6.0\n",
    "# python-dotenv==1.0.0\n",
    "# langchain==0.1.16\n",
    "# langchain-core==0.1.46\n",
    "# langchain-community==0.0.34\n",
    "# langchain-openai==0.1.4\n",
    "# qdrant-client==1.9.0\n",
    "# pymupdf==1.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /home/bull/anaconda3/envs/Meta-10k-RAG/lib/python3.9/site-packages (1.24.2)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /home/bull/anaconda3/envs/Meta-10k-RAG/lib/python3.9/site-packages (from pymupdf) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "import chainlit as cl\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import tiktoken\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "import os\n",
    "import openai\n",
    "from getpass import getpass\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = getpass(\"OpenAI API Key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 20:23:43 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:23:45 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:23:47 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:23:49 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "openai_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "openai_chat_model_4 = ChatOpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "docs = PyMuPDFLoader(\"Meta10k.pdf\").load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 50,\n",
    "    length_function = tiktoken_len,\n",
    ")\n",
    "\n",
    "split_chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    split_chunks, \n",
    "    embedding_model, \n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Meta10k\",\n",
    ")\n",
    "\n",
    "# THE SECRET SAUCE\n",
    "qdrant_retriever = qdrant_vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={'k': 6, 'lambda_mult': 0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = \"\"\"\n",
    "You are an expert financial analyst.  You will be provided CONTEXT excerpts from the META company 10K annual report.  Your job is to answer the QUERY as correctly as you can using the information provided by the CONTEXT and your skills as an expert financial analyst.  For questions regarding money do not over think it and begin adding values unless you are specifically asked to.  Use the simplest most obvious choice. IF the context provided does give you enough information to answer the question, respond \"I do not know\"\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "EVAL_SYSTEM_TEMPLATE = \"\"\"You are an expert in analyzing the quality of a response.\n",
    "\n",
    "You should be hyper-critical.\n",
    "\n",
    "Provide scores (out of 10) for the following attributes:\n",
    "\n",
    "1. Clarity - how clear is the response\n",
    "2. Faithfulness - how related to the original query is the response and the provided context\n",
    "3. Correctness - was the response correct?\n",
    "\n",
    "Please take your time, and think through each item step-by-step, when you are done - please provide your response in the following format:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "EVAL_USER_TEMPLATE = \"\"\"Query: {input}\n",
    "Context: {context}\n",
    "Response: {response}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
    "eval_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", EVAL_SYSTEM_TEMPLATE),\n",
    "    (\"human\", EVAL_USER_TEMPLATE)\n",
    "])\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=qdrant_retriever, llm=openai_chat_model)\n",
    "\n",
    "chain = ({\"context\": itemgetter(\"question\") | retriever_from_llm, \"question\": itemgetter(\"question\")} | RunnablePassthrough.assign(context=itemgetter(\"context\")) | {\"response\": rag_prompt | openai_chat_model, \"context\": itemgetter(\"context\")})\n",
    "eval_chain = eval_prompt | openai_chat_model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 20:27:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:27:50 - Generated queries: [\"1. Can you provide the total amount of 'Cash and cash equivalents' on December 31, 2023?\", \"2. How much was the value of 'Cash and cash equivalents' on December 31, 2023?\", \"3. What was the total worth of 'Cash and cash equivalents' as at December 31, 2023?\"]\n",
      "2024-05-01 20:27:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:27:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:27:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:27:52 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:28:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#Question #1\n",
    "\n",
    "response = chain.invoke({\"question\":\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\"})\n",
    "\n",
    "context = \"\\n\".join([context.page_content for context in response[\"context\"]])\n",
    "eval_response = eval_chain.invoke({\"input\":\"What was the total value of 'Cash and cash equivalents' as of December 31, 2023?\", \"context\":context, \"response\":response[\"response\"].content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The total value of 'Cash and cash equivalents' as of December 31, 2023, was $41,862 million.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from LLM\n",
    "response[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Clarity: 9/10\\nThe response is clear and concise, directly stating the total value of 'Cash and cash equivalents' as of December 31, 2023. It provides a specific figure which is easily understandable.\\n\\nFaithfulness: 10/10\\nThe response is completely faithful to the original query and the provided context. It precisely addresses the query by extracting the exact figure from the context without adding any unrelated information.\\n\\nCorrectness: 10/10\\nThe response is correct as it accurately reports the value of 'Cash and cash equivalents' as $41,862 million, which matches the data provided in the context. \\n\\nOverall, the response effectively communicates the required information and is both accurate and relevant to the query.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM evaluating my original response\n",
    "eval_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 20:31:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:31:32 - Generated queries: [\"1. Can you provide a list of individuals who serve as 'Directors' at Meta, also known as members of the Board of Directors?\", \"2. Who makes up the group of 'Directors' at Meta, specifically referring to the members of the Board of Directors?\", \"3. Could you share the names of the individuals who hold the title of 'Directors' at Meta, in other words, the members of the Board of Directors?\"]\n",
      "2024-05-01 20:31:32 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:31:32 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:31:32 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:31:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-05-01 20:31:46 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#Question #2\n",
    "response = chain.invoke({\"question\":\"Who are Meta's 'Directors' (i.e., members of the Board of Directors)?\"})\n",
    "\n",
    "context = \"\\n\".join([context.page_content for context in response[\"context\"]])\n",
    "eval_response = eval_chain.invoke({\"input\":\"Who are Meta's 'Directors' (i.e., members of the Board of Directors)?\", \"context\":context, \"response\":response[\"response\"].content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The members of Meta's Board of Directors, as listed in the document, include:\\n1. Mark Zuckerberg\\n2. Susan Li\\n3. Aaron Anderson\\n4. Peggy Alford\\n5. Marc L. Andreessen\\n6. Andrew W. Houston\\n7. Nancy Killefer\\n8. Robert M. Kimmitt\\n9. Sheryl K. Sandberg\\n10. Tracey T. Travis\\n11. Tony Xu\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Response from LLM for question #2\n",
    "response[\"response\"].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. Clarity - 9/10\\n   - The response is quite clear and lists the members of Meta's Board of Directors succinctly. Each name is presented in an easy-to-read format.\\n\\n2. Faithfulness - 10/10\\n   - The response accurately captures and relays information directly relevant to the query about the members of Meta's Board of Directors. It correctly uses the information provided in the context.\\n\\n3. Correctness - 6/10\\n   - The response inaccurately includes Susan Li and Aaron Anderson as members of Meta's Board of Directors. Susan Li is listed as the Chief Financial Officer and Aaron Anderson as the Chief Accounting Officer in the document, not as board members. The correct response should have excluded these two names from the list of directors.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eval of response #2\n",
    "eval_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Meta-10k-RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
